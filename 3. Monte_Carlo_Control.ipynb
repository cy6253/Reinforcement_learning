{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3. Monte_Carlo_Control.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMNhtFsva4ljqD6biOjY2y/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"q-XfWLELQGqR","executionInfo":{"status":"ok","timestamp":1625438122586,"user_tz":-540,"elapsed":2,"user":{"displayName":"조용현","photoUrl":"","userId":"01571572261859641621"}}},"source":["import random\n","import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"CltE0ijqoZdj","executionInfo":{"status":"ok","timestamp":1625438122587,"user_tz":-540,"elapsed":2,"user":{"displayName":"조용현","photoUrl":"","userId":"01571572261859641621"}}},"source":["class GridWorld():\n","    def __init__(self):\n","        self.x=0\n","        self.y=0\n","    \n","    def step(self, a):\n","        if a==0:\n","            self.move_left()\n","        elif a==1:\n","            self.move_up()\n","        elif a==2:\n","            self.move_right()\n","        elif a==3:\n","            self.move_down()\n","\n","        reward = -1  \n","        done = self.is_done()\n","        return (self.x, self.y), reward, done\n","\n","    def move_left(self):\n","        if self.y==0:\n","            pass\n","        elif self.y==3 and self.x in [0,1,2]:\n","            pass\n","        elif self.y==5 and self.x in [2,3,4]:\n","            pass\n","        else:\n","            self.y -= 1\n","\n","    def move_right(self):\n","        if self.y==1 and self.x in [0,1,2]:\n","            pass\n","        elif self.y==3 and self.x in [2,3,4]:\n","            pass\n","        elif self.y==6:\n","            pass\n","        else:\n","            self.y += 1\n","      \n","    def move_up(self):\n","        if self.x==0:\n","            pass\n","        elif self.x==3 and self.y==2:\n","            pass\n","        else:\n","            self.x -= 1\n","\n","    def move_down(self):\n","        if self.x==4:\n","            pass\n","        elif self.x==1 and self.y==4:\n","            pass\n","        else:\n","            self.x+=1\n","\n","    def is_done(self):\n","        if self.x==4 and self.y==6:\n","            return True\n","        else:\n","            return False\n","      \n","    def reset(self):\n","        self.x = 0\n","        self.y = 0\n","        return (self.x, self.y)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"2U6sd5_TSaR_"},"source":["class QAgent():\n","    def __init__(self):\n","        self.q_table = np.zeros((5, 7, 4)) # 각 state마다 action table\n","        self.eps = 0.9  # 입실론 : 0.9로 시작\n","        self.alpha = 0.01\n","        self.gamma = 1\n","        \n","    def select_action(self, s):\n","        x, y = s\n","        coin = random.random()\n","        if coin < self.eps: # 입실론보다 작으면 랜덤하게 선택\n","            action = random.randint(0,3)\n","        else:\n","            action_val = self.q_table[x,y,:] # 입실론보다 크면 \n","            action = np.argmax(action_val) # 현재 state의 action에서 가장 큰 값 선택\n","        \n","        return action\n","\n","    def update_table(self, history): # history를 받음\n","        cum_reward = 0 # 리턴\n","        for transition in history[::-1]: # 뒤에서부터\n","            s, a, r, s_prime = transition # state, action, reward, next_state\n","            x,y = s # 현재 state\n","            self.q_table[x,y,a] = self.q_table[x,y,a] + self.alpha * (cum_reward - self.q_table[x,y,a]) # q_table 업데이트\n","            cum_reward = r + self.gamma*cum_reward\n","\n","    def anneal_eps(self): # decaying epsilon\n","        self.eps -= 0.03\n","        self.eps = max(self.eps, 0.1)\n","\n","    def show_table(self):\n","        q_lst = self.q_table.tolist() # shape = (5,7,4)\n","        data = np.zeros((5,7))\n","        for row_idx in range(len(q_lst)):\n","            row = q_lst[row_idx]\n","            for col_idx in range(len(row)):\n","                col = row[col_idx]\n","                action = np.argmax(col)\n","                data[row_idx, col_idx] = action\n","        print(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mL_dh3bgSaVg"},"source":["def main():\n","    env = GridWorld()\n","    agent = QAgent()\n","    epi = 100000\n","    for n_epi in range(epi): # episode\n","        done = False\n","        history = []\n","\n","        s = env.reset()\n","        while not done: # 에이전트 경험 쌓기\n","            a = agent.select_action(s) # 주어진 state에서 action\n","            s_prime, r, done = env.step(a) # next_state, reward, 종료여부 반환\n","            history.append((s, a, r, s_prime))\n","            s = s_prime\n","        agent.update_table(history) # Q_table 업데이트\n","        agent.anneal_eps() # decaying epsilon\n","\n","    agent.show_table()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t1tRZUmySaYo","executionInfo":{"status":"ok","timestamp":1625209791996,"user_tz":-540,"elapsed":10488,"user":{"displayName":"조용현","photoUrl":"","userId":"01571572261859641621"}},"outputId":"a6ae77f9-f29c-4a8f-c2c9-70d31768161a"},"source":["main()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[2. 3. 0. 2. 2. 2. 3.]\n"," [2. 3. 0. 2. 2. 3. 3.]\n"," [2. 3. 0. 1. 0. 3. 3.]\n"," [2. 2. 2. 1. 0. 3. 3.]\n"," [1. 1. 2. 1. 0. 2. 0.]]\n"],"name":"stdout"}]}]}